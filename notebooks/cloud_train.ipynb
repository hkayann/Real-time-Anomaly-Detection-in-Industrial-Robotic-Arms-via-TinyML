{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example to generate/edit/upload to `model.cc` file Google Drive.\n",
    "\n",
    "Our implementation requires setting up a Google Cloud project as we use Google Drive as storage, authorization is done over `OAuth 2.0`.\n",
    "\n",
    "Check the following page to learn how to set up a project: [Google's OAuth 2.0 protocols](https://developers.google.com/identity/protocols/oauth2).\n",
    "\n",
    "The default `model.cc` need some tweaking. This is an example notebook, where example model is used that shows how to generate ready-to-use `model.cc` file.\n",
    "\n",
    "This file contains our model and required parameters for scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from urllib.request import urlopen\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from google_auth_oauthlib.flow import Flow\n",
    "from googleapiclient.errors import HttpError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 10:28:25.839939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46646 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 10:28:28.146986: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f27899e6030 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-31 10:28:28.147016: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2024-03-31 10:28:28.151586: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-31 10:28:28.169126: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711880908.254985 1453555 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 3s 12ms/step - loss: 0.0396 - val_loss: 0.0111\n",
      "Epoch 2/5\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 3/5\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 4/5\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 5/5\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.0107 - val_loss: 0.0102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f287e5cc350>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "# Fetch dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv\"\n",
    "data = pd.read_csv(urlopen(url))\n",
    "\n",
    "# Preprocess data\n",
    "# For simplicity, let's predict the temperature based on the last 5 days.\n",
    "def create_dataset(X, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(X.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 5\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[['Temp']].values)\n",
    "\n",
    "# Create dataset for LSTM\n",
    "X, y = create_dataset(pd.DataFrame(scaled_data), time_steps)\n",
    "\n",
    "# Split dataset (let's use the first 80% of the data for training and the rest for testing)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Define LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: /tf/models/lstm_ex/model.tflite\n",
      "Size of the TFLite model: 52008 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 10:32:15.876198: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-03-31 10:32:15.876229: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-03-31 10:32:15.876389: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tf/models/lstm_ex\n",
      "2024-03-31 10:32:15.878403: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-03-31 10:32:15.878418: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tf/models/lstm_ex\n",
      "2024-03-31 10:32:15.883733: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-03-31 10:32:15.921325: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tf/models/lstm_ex\n",
      "2024-03-31 10:32:15.937818: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 61429 microseconds.\n",
      "2024-03-31 10:32:16.068167: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-31 10:32:16.068259: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 23, Total Ops 61, % non-converted = 37.70 %\n",
      " * 20 ARITH ops, 3 TF ops\n",
      "\n",
      "- arith.constant:   20 occurrences  (f32: 6, i32: 14)\n",
      "\n",
      "  (i1: 1, i32: 1)\n",
      "\n",
      "\n",
      "- tf.TensorListReserve:    1 occurrences  (: 1)\n",
      "- tf.TensorListSetItem:    1 occurrences  (: 1)\n",
      "- tf.TensorListStack:    1 occurrences  (f32: 1)\n",
      "  (f32: 3, i32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n",
      "  (i1: 1)\n",
      "  (f32: 3)\n",
      "  (f32: 3)\n",
      "\n",
      "  (i32: 1)\n",
      "  (f32: 2)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1, i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "\n",
      "2024-03-31 10:32:16.069949: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2921] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x50xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x50xf32>>>, tensor<i32>, tensor<?x50xf32>) -> (tensor<!tf_type.variant<tensor<?x50xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x50xf32>>>, tensor<2xi32>) -> (tensor<1x?x50xf32>) : {device = \"\", num_elements = 1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
     ]
    }
   ],
   "source": [
    "# Model directory to save the TensorFlow SavedModel\n",
    "MODEL_DIR = \"/tf/models/lstm_ex\"\n",
    "model.save(MODEL_DIR, save_format=\"tf\")\n",
    "\n",
    "# Convert the SavedModel to a TensorFlow Lite model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "\n",
    "# Enable Select TensorFlow operations\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS     # Enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "# Disable lowering tensor list operations\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Path to save the TFLite model\n",
    "tflite_model_path = \"/tf/models/lstm_ex/model.tflite\"\n",
    "\n",
    "# Save the TFLite model to the file\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Get the size of the TFLite model file\n",
    "tflite_file_size = os.path.getsize(tflite_model_path)\n",
    "\n",
    "print(f\"Model saved to: {tflite_model_path}\")\n",
    "print(f\"Size of the TFLite model: {tflite_file_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ignore the above warnings. Now the below command generates our file but requires a tweaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i /tf/models/lstm_ex/model.tflite > /tf/models/lstm_ex/model.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required tweaks are:\n",
    "- Including header file.\n",
    "- Changing model parameter name.\n",
    "- Adding scaling paramaters.\n",
    "\n",
    "In actual scenario, the scaling parameters would be fetch from the main *training* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original file\n",
    "with open('/tf/models/lstm_ex/model.cc', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Flag to check if sensor values already exist\n",
    "sensor_values_exist = any(\"ACCX_MEAN\" in line for line in lines)\n",
    "\n",
    "# Add the missing include at the beginning if not already present\n",
    "if not any(line.strip() == '#include \"model.h\"' for line in lines):\n",
    "    lines.insert(0, '#include \"model.h\"\\n')\n",
    "\n",
    "# Modify the variable declaration if needed\n",
    "variable_declaration = 'alignas(16) const char g_model[] = {\\n'\n",
    "if not any(variable_declaration in line for line in lines):\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('unsigned char _tf_models_lstm_ex_model_tflite[]'):\n",
    "            lines[i] = variable_declaration\n",
    "            break\n",
    "\n",
    "# Append sensor mean and standard deviation values at the end if they do not exist\n",
    "if not sensor_values_exist:\n",
    "    sensor_values = \"\"\"\n",
    "// Accelerometer X-axis\n",
    "const float ACCX_MEAN = 9.235880f;    \n",
    "const float ACCX_STD = 1.516386f;    \n",
    "\n",
    "// Accelerometer Y-axis\n",
    "const float ACCY_MEAN = -0.682526f;    \n",
    "const float ACCY_STD = 3.083149f;      \n",
    "\n",
    "// Accelerometer Z-axis\n",
    "const float ACCZ_MEAN = 0.4874396f;    \n",
    "const float ACCZ_STD = 0.234757f;      \n",
    "\n",
    "// Gyroscope X-axis\n",
    "const float GYROX_MEAN = 0.344743f;  \n",
    "const float GYROX_STD = 28.02007f;    \n",
    "\n",
    "// Gyroscope Y-axis\n",
    "const float GYROY_MEAN = 0.666154f; \n",
    "const float GYROY_STD = 8.086139f;  \n",
    "\n",
    "// Gyroscope Z-axis\n",
    "const float GYROZ_MEAN = 0.011609f; \n",
    "const float GYROZ_STD = 26.38441f;      \n",
    "\n",
    "// Magnetometer X-axis\n",
    "const float MAGX_MEAN = -33.35714f;  \n",
    "const float MAGX_STD = 5.843046f;    \n",
    "\n",
    "// Magnetometer Y-axis\n",
    "const float MAGY_MEAN = 19.60439f;  \n",
    "const float MAGY_STD = 19.29037f;    \n",
    "\n",
    "// Magnetometer Z-axis\n",
    "const float MAGZ_MEAN = -2.507685f;  \n",
    "const float MAGZ_STD = 31.47144f;\n",
    "\"\"\"\n",
    "    lines.append(sensor_values)\n",
    "\n",
    "# Write the modified content back\n",
    "with open('/tf/models/lstm_ex/model.cc', 'w') as file:\n",
    "    file.writelines(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the authorization is done. \n",
    "\n",
    "Get your token if you are running for the first time, then repeated accesses will not require any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "\n",
    "creds = None\n",
    "if os.path.exists('/tf/token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('/tf/token.json', SCOPES)\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = Flow.from_client_secrets_file(\n",
    "            '/tf/credentials.json', \n",
    "            scopes=SCOPES,\n",
    "            redirect_uri='urn:ietf:wg:oauth:2.0:oob')\n",
    "        \n",
    "        auth_url, _ = flow.authorization_url(prompt='consent')\n",
    "\n",
    "        print('Please go to this URL and authorize the app:')\n",
    "        print(auth_url)\n",
    "        auth_code = input('Enter the authorization code: ')\n",
    "        flow.fetch_token(code=auth_code)\n",
    "        \n",
    "        creds = flow.credentials\n",
    "        with open('/tf/token.json', 'w') as token_file:\n",
    "            token_file.write(creds.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then upload our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ID: 105L9d3JU8n2AMqf8NiZbJGeVSa2_rVEs\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Step 1: Set up the Drive service\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    # Step 2: Define file metadata and media content\n",
    "    file_metadata = {'name': 'model.cc'}\n",
    "    media = MediaFileUpload('/tf/models/lstm_ex/model.cc', mimetype='text/plain')\n",
    "    \n",
    "    # Step 3: Execute the upload\n",
    "    file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "    \n",
    "    # Print the uploaded file ID\n",
    "    print(f'File ID: {file.get(\"id\")}')\n",
    "except HttpError as error:\n",
    "    # Handle errors from the Drive API.\n",
    "    print(f'An error occurred: {error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our file ready in cloud to be downloaded to fog node where we do OTA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
